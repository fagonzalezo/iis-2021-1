---
id: schedule
name: Calendario
heading: Calendario del curso
subheading: 
image: 
---
<table class="table table-condensed">
	<tbody>
		<tr>
			<th>Semana</th>
			<th>Tema</th>
			<th>Material</th>
			<th>Actividades</th>
		</tr>
		<small>
			<tr>
				<td>Feb 22</td>
				<td>1. Introducción</td>
				<td>
					Clase Feb 22 (<a href= "https://drive.google.com/file/d/13A6w8qpi3etVAFLPsPcvohYGe0Lkr0RL/view?usp=sharing">video</a>)
					[Russell10] Chap 1 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter01.pdf">slides</a>)<br>
					[AI-edX] Introduction to AI (<a href= "http://ai.berkeley.edu/slides/Lecture%201%20--%20Introduction/SP14%20CS188%20Lecture%201%20--%20Introduction.pptx">slides</a>) (<a href= "https://edge.edx.org/courses/course-v1:BerkeleyX+CS188x-SP16+SP16/courseware/a2dc8e2add91416a8f2a64410b3bf8e0/b414886f442a41e4b5fd0408de837e53/">video</a>)<br>
					<a href= "https://github.com/fagonzalezo/iis-2018-2/raw/master/catedra-cc-unal.pdf">Inteligencia Artificial</a>, Fabio González, (<a href= "https://drive.google.com/file/d/16wHaIRn0GCoephK_uLCROw9V6CcvTf37/view?usp=sharing">video</a>)<br> 
					<a href= "https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn">The Wonderful and Terrifying Implications of Computers That Can Learn</a>, Jeremy Howard, TED	<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Mar 1</td>
				<td>1.3 Agentes inteligentes<br>
				</td>
				<td>
					[Russell10] Chap 2 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter02.pdf">slides</a>) <br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Mar 8</td>
				<td>2.1 Agentes y Búsquedas<br>
					2.4 Búsqueda no informada<br>
				</td>
				<td>
					[AI-edX] Agents and Search (<a href= "http://ai.berkeley.edu/slides/Lecture%202%20--%20Uninformed%20Search/SP14%20CS188%20Lecture%202%20--%20Uninformed%20Search.pptx">slides</a>) (<a href= "https://edge.edx.org/courses/course-v1:BerkeleyX+CS188x-SP16+SP16/courseware/a2dc8e2add91416a8f2a64410b3bf8e0/7c56230af88d467c9737344e2e76092e/">video</a>)<br>					[Russell10] Chap 3 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter03.pdf">slides</a>)  and Chap 4 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter04a.pdf">slides</a>) <br>
					<a href= "https://github.com/aimacode/aima-python/blob/master/search4e.ipynb">Search algorithms notebook from AIMA </a><br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Mar 15</td>
				<td>
				2.5 Búsqueda informada<br> 
				</td>
				<td>
					[Russell10] Chap 3 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter03.pdf">slides</a>)  and Chap 4 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter04a.pdf">slides</a>) <br>
					[AI-edX] A* Search and Heuristics (<a href= "http://ai.berkeley.edu/slides/Lecture%203%20--%20Informed%20Search/SP14%20CS188%20Lecture%203%20--%20Informed%20Search.pptx">slides</a>) (<a href= "https://edge.edx.org/courses/course-v1:BerkeleyX+CS188x-SP16+SP16/courseware/a2dc8e2add91416a8f2a64410b3bf8e0/76f9a53b7aad47638ff968db5938d841/">video</a>)<br>
					<a href= "https://github.com/aimacode/aima-python/blob/master/search4e.ipynb">Search algorithms notebook from AIMA </a>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Mar 22</td>
				<td>3.1 Qué es aprendizaje de máquina<br>
					3.2 Aprendizaje supervisado<br>
				</td>
				<td>
					[Russell10] Sect 18.1, 18.2, 18.6 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter18.pdf">slides</a>) <br>
					An Introduction to Machine Learning (<a href= "https://fagonzalezo.github.io/iis-2019-1/intro-ml.pdf">slides</a>)<br>
					<a href= "https://colab.research.google.com/drive/1J4p2g0xbRUS5u6-whz9vWUABiGZvuneA?usp=sharing">Notebook: Clasificación binaria usando un modelo lineal</a><br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Abr 5</td>
				<td>
				3.2.1 Clasificación lineal<br>
				3.2.2 Modelos probabilísticos (regresión logística, Naïve Bayes)<br>
				</td>
				<td>
					[Russell10] Sect 18.6 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter18.pdf">slides</a>) 20.2 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter20a.pdf">slides</a>)<br>
					Naïve Bayes (<a href= "https://www-users.cs.umn.edu/~kumar001/dmbook/dmslides/chap5_alternative_classification.pdf">slides 49-60</a>)<br>
					<a href= "https://colab.research.google.com/drive/1nkxk-h0cBICX2uTCSWaIF6YXhKNMhR8u?usp=sharing">Notebook: Clasificación Lineal y Evaluación del Desempeño</a>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Abr 12</td>
				<td>3.2.3 Clasificación no lineal (k-nn, árboles de decisión)<br>
				</td>
				<td>
					Árboles de Decisión (<a href= "https://drive.google.com/file/d/1RyjxtIVIjmvObChOfuf0lWveXMbWpxhs/view">video</a>)<br>
					[Russell10] Sect 18.3 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter18.pdf">slides</a>) <br>
					<a href= "https://colab.research.google.com/drive/1pvTLE_jx2cdnU3jCZ9T1hQk3d3jIxoh7">Notebook: Clasificación no lineal, complejidad y sobreajuste</a><br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Abr 19</td>
				<td>
					3.2.4 Support vector machines<br>
					3.2.5 Random Forest
				</td>
				<td>
					[Russell10] Sect 18.9 y 18.10 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter18.pdf">slides</a>) <br>
					<a href= "https://colab.research.google.com/drive/1kfy-4I9OyP7rQTdbsNs5UoM6GVi0Ig4P?usp=sharing">Notebook: Máquinas de vectores de soporte y selección de modelos</a><br>
					<a href= "https://colab.research.google.com/drive/1MCfPiwOIG-v77YLUFW7iJmGVewiWAYbE">Notebook: Random Forests y exploración aleatorizada</a><br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Abr 26</td>
				<td>3.2.6 Redes neuronales<br>
				</td>
				<td>
					[Russell10] Sect 18.6 (<a href= "http://aima.eecs.berkeley.edu/slides-pdf/chapter18.pdf">slides</a>) <br>
					[Alp10] Chap 11  (<a href= "https://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap11-v1-0.pdf">slides</a>) <br>
					<a href= "https://playground.tensorflow.org/">Neural Network Playground</a><br>
					<a href= "https://colab.research.google.com/drive/167WK7Ts3Z5gVhPshFwFh0F36PyzZev_4?usp=sharing">Notebook: Redes Neuronales</a><br>
					<a href= "https://colab.research.google.com/drive/1LzTwgL3jL1L58lQqe29F4TXw_KqA08ak">Notebook: Neural Networks in Keras</a><br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>May 3-May 17</td>
				<td>3.2.7 Deep learning<br>
				</td>
				<td>
					Introduction to Deep Learning and Applications (<a href= "https://github.com/albahnsen/AppliedDeepLearningClass/blob/master/presentations/DL-introduction.pdf">slides</a>) <br>
					<a href= "https://fagonzalezo.github.io/dl_tutorial_upv/">Representation Learning and Deep Learning Tutorial </a><br>
					<a href= "https://colab.research.google.com/drive/1C8MOfKYY-Pb9dlNBli8pF8YYpYVCJuhp">Notebook: CNN for image classification in Keras</a><br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>May 24</td>
				<td>3.2.7 Deep learning<br>
				</td>
				<td>
				Deep learning frameworks (<a href= "https://github.com/fagonzalezo/ml-2020-1/raw/master/ML%20Deep%20Learning%20Frameworks.pdf">slides</a>)<br>
				Introduction to TensorFlow (<a href= "https://colab.research.google.com/drive/1cjmAU2v0oDZawN9AAZshz4t6AhqDOBf-">Jupyter notebook</a>)<br>
				Neural Networks in Keras (<a href= "https://colab.research.google.com/drive/1iOIVyQ19GGkY_5knuLRo0HP3BouJlpwy">Jupyter notebook</a>)<br>
				</td>
				<td>
				</td>
			</tr>
            <tr>
				<td>May 31</td>
				<td>
				3.3 Aprendizaje no supervisado <br>
				3.3.2 Clustering (agrupamiento)<br>
				</td>
				<td>
					<br>
					<a href= "https://fagonzalezo.github.io/iis-2018-1/KMeans.pdf">K-Means</a><br>
					<a href= "https://colab.research.google.com/drive/1_0Ipc_RqFNwBrVAc3HY4rZfDpKLHrbgR?usp=sharing">Notebook: Agrupamiento</a><br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Jun 7</td>
				<td>
				    3.3.1 Reducción de la dimensionalidad <br>
				</td>
				<td>
					Intro to PCA (<a href= "https://www.scribd.com/presentation/62790749/Intro-to-PCA">slides</a>)
					<br>
					A tutorial on principal component analysis (<a href= "https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf">pdf</a>)<br>
					Reducción de la dimensionalidad con PCA (<a href= "https://colab.research.google.com/drive/1UO8TZ4oRsjHhDOaIbU3xM0Ndsf_5QQb8">notebook</a>)
				</td>
				<td>
				</td>				
			</tr>
			<tr>
				<td>Jun 14</td>
				<td>
				</td>
				<td>
				</td>
				<td>
				</td>				
			</tr>
		</small>
	</tbody>
</table>
